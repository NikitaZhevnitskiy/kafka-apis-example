# Kafka cluster by landoop
version: '3'
services:
  kafka-cluster:
    image: landoop/fast-data-dev:2.1.0
    environment:
      ADV_HOST: localhost         # Change to 192.168.99.100 if using Docker Toolbox
      RUNTESTS: 0                 # Disable Running tests so the cluster starts faster
      DISABLE: azure-documentdb,blockchain,bloomberg,cassandra,coap,druid,elastic,elastic5,ftp,hazelcast,hbase,influxdb,kudu,mongodb,mqtt,redis,rethink,voltdb,yahoo,hdfs,elasticsearch,s3,twitter
    ports:
      - "2181:2181"                 # Zookeeper
      - "3030:3030"                 # Landoop UI
      - "8081-8083:8081-8083"       # REST Proxy, Schema Registry, Kafka Connect ports
      - "9581-9585:9581-9585"       # JMX Ports
      - "9092:9092"                 # Kafka Broker
    volumes:
      - ./kafka-connect/kafka-connect-mq-source-1.0.1-uber.jar:/connectors/kafka-connect-mq-source-1.0.1-uber.jar

  postgres:
    image: postgres:11
    environment:
      POSTGRES_USER: postgres     # define credentials
      POSTGRES_PASSWORD: postgres # define credentials
      POSTGRES_DB: postgres       # define database
    ports:
      - 5432:5432                 # Postgres port

  # IBM MQ
  ibm-mq:
    image: ibmcom/mq:9
    environment:
      LICENSE: accept
      MQ_QMGR_NAME: QM1
      #      Prometheus metrics, exposed on :9157/metrics
      MQ_ENABLE_METRICS: "true"
    ports:
      - 1414:1414
      - 9443:9443
      - 9157:9157

  connect:
    image: confluentinc/cp-kafka-connect:5.1.0
    container_name: connect
    hostname: connect
    volumes:
      - ./kafka-connect/kafka-connect-mq-source-1.0.1-uber.jar:/usr/share/java/kafka-connect-ibm-mq/kafka-connect-mq-source-1.0.1-uber.jar
    ports:
      - 18083:8083
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'kafka-cluster:9092'
      CONNECT_REST_PORT: 8083
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_GROUP_ID: separate-connect
      CONNECT_CONFIG_STORAGE_TOPIC: separate-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: separate-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: separate-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://kafka-cluster:8081'
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_ZOOKEEPER_CONNECT: 'kafka-cluster:2181'
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components,/etc/kafka-connect/jars"
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-5.0.0.jar
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR